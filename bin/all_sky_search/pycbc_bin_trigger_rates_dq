#!/usr/bin/env python
""" Bin triggers by their dq logl and calculate trigger rates in each bin
"""
import logging
import argparse
import pycbc
import pycbc.events
from pycbc.events import ranking
import numpy as np
import h5py as h5
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pycbc.version import git_verbose_msg as version

parser = argparse.ArgumentParser(description=__doc__)
parser.add_argument('--version', action='version', version=version)
parser.add_argument('--verbose', action="store_true")
parser.add_argument("--ifo", type=str,required=True)
parser.add_argument("--trig-file", required=True)
parser.add_argument("--sngl-stat", default="new_snr",
                    choices=ranking.sngls_ranking_function_dict.keys(),
                    help="Function of SNR and chisq to threshold on")
parser.add_argument("--stat-threshold", type=float,
                    help="Only consider triggers with statistic value above this "
                    "threshold")
parser.add_argument("--dq-file", required=True,nargs='+')
parser.add_argument('--bank-file', help='hdf format template bank file',
                    required=True)
parser.add_argument('--background-bins', nargs='+', help='list of background bin format strings')
parser.add_argument("--output-file", required=True)
parser.add_argument("--output-plot")
parser.add_argument("--prune-number", type=int, default=0,
                    help="Number of loudest events to remove from each split "
                         "histogram, default 0")
parser.add_argument("--prune-window", type=float, default=0.1,
                    help="Time (s) to remove all triggers around a trigger "
                         "which is loudest in each split, default 0.1s")

args = parser.parse_args()
pycbc.init_logging(args.verbose)

bank = h5.File(args.bank_file, 'r')

if args.background_bins:
    logging.info('Sorting bank into bins...')
    data = {'mass1': bank['mass1'][:], 'mass2': bank['mass2'][:],
            'spin1z': bank['spin1z'][:], 'spin2z': bank['spin2z'][:],
            'f_lower': bank['f_lower']}
    locs_dict = pycbc.events.background_bin_from_string(args.background_bins, data)
    del data
    locs_names = [b.split(':')[0] for b in args.background_bins]
else:
    locs_dict = {'all_bin': np.arange(0, len(bank['mass1'][:]), 1)}
    locs_name = ['all_bin']

logging.info('Reading trigger file...')
ifo = args.ifo
trig_file = h5.File(args.trig_file,'r')
trig_times = trig_file[ifo+'/end_time'][:]
trig_ids = trig_file[ifo+'/template_id'][:]

if args.stat_threshold or args.prune_number>0:
    logging.info('Calculating stat and filtering...')
    stat = ranking.get_sngls_ranking_from_trigs(trig_file[ifo],
                                                args.sngl_stat)
    if args.stat_threshold:
        abovethresh = stat >= args.stat_threshold
        trig_ids = trig_ids[abovethresh]
        trig_times = trig_times[abovethresh]
        stat = stat[abovethresh]
trig_file.close()

trig_times_int = trig_times.astype('int')
del trig_times

dq_times = np.array([])
dq_logl = np.array([])

for filename in args.dq_file:
    logging.info('Reading DQ file %s...'%filename)
    g = h5.File(filename, 'r')
    g_logl = g[ifo + '/dq_val'][:]
    g_times = g[ifo + '/times'][:]
    g.close()
    dq_logl = np.concatenate((dq_logl,g_logl))
    dq_times = np.concatenate((dq_times,g_times))
del g_logl
del g_times

percent_bin = 0.5
n_bins = int(100./percent_bin)
percentiles = np.linspace(0,100,n_bins+1)
bin_times = np.zeros(n_bins)
dq_percentiles = np.percentile(dq_logl,percentiles)

    
# seconds bin tells what bin each second ends up
seconds_bin = [len(dq_percentiles[dq_percentiles < dq_ll]) for dq_ll in dq_logl]

# bin times tells how much time ends up in each bin. Set any bin with zero seconds to 1 second
# to avoid divide by zero error when calculating rates
bin_times = [len(seconds_bin[seconds_bin==(i+1)]) for i in range(n_bins)]
bin_times[bin_times==0]=1

# create a dict to look up dq percentile at any time
dq_percentiles_time = dict(zip(dq_times, seconds_bin*percent_bin/100))

del dq_times
del dq_logl
del dq_percentiles
               
if args.prune_number>0:
    for bin_name in locs_names:
        logging.info('Processing bin %s...'%bin_name)
        bin_locs = locs_dict[bin_name]
        trig_times_bin = trig_times_int[np.isin(trig_ids, bin_locs)] 
        trig_stats_bin = stat[np.isin(trig_ids, bin_locs)]
    
        for j in range(args.prune_number):        
            max_stat_arg = np.argmax(trig_stats_bin)
            remove = np.nonzero(abs(trig_times_bin[max_val_arg] - trig_times_int)
                               < args.prune_window)[0]
            remove_inbin = np.nonzero(abs(trig_times_bin[max_val_arg] - trig_times_bin_int)
                               < args.prune_window)[0]
            stat[remove] = 0
            trig_stats_bin[remove_inbin] = 0
    keep = np.nonzero(stat)[0]
    trig_times_int = trig_times_int[keep]
    trig_ids = trig_ids[keep]
    del stat
    del keep
               
f = h5.File(args.output_file,'w')        
for bin_name in locs_names:
    bin_locs = locs_dict[bin_name]
    trig_times_bin = trig_times_int[np.isin(trig_ids, bin_locs)] 
    trig_percentile = [dq_percentiles_time[t] for t in trig_times_bin]
    logging.info('Processing %d triggers...'%len(trig_percentile))
               
    (counts, bins) = np.histogram(trig_percentile, bins = percentiles/100.)
    rates = counts/bin_times
    rates/=np.mean(rates)
    
    logging.info('Writing rates to output file %s...'%args.output_file)
    grp = f.create_group(bin_name)
    grp['rates']=rates
    grp['locs']=locs_dict[bin_name]
 
f.attrs['names'] = locs_names
f.close()
